{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 5\n",
    "\n",
    "# K-Nearest Neighbors Method\n",
    "\n",
    "## 5.1 A Basic k-NN Classifier\n",
    "\n",
    "### 5.1.1 The _\"Can I eat that?\" App_\n",
    "\n",
    "We start by exploring the mushrooms dataset and looking at a random sample of the data and understand what is there"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>E</th>\n",
       "      <th>F0</th>\n",
       "      <th>F1</th>\n",
       "      <th>F2</th>\n",
       "      <th>F3</th>\n",
       "      <th>F4</th>\n",
       "      <th>F5</th>\n",
       "      <th>F6</th>\n",
       "      <th>F7</th>\n",
       "      <th>F8</th>\n",
       "      <th>...</th>\n",
       "      <th>F12</th>\n",
       "      <th>F13</th>\n",
       "      <th>F14</th>\n",
       "      <th>F15</th>\n",
       "      <th>F16</th>\n",
       "      <th>F17</th>\n",
       "      <th>F18</th>\n",
       "      <th>F19</th>\n",
       "      <th>F20</th>\n",
       "      <th>F21</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3156</th>\n",
       "      <td>p</td>\n",
       "      <td>x</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>n</td>\n",
       "      <td>g</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8088</th>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>o</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3247</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>y</td>\n",
       "      <td>n</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>u</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>g</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>965</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>n</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>k</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1189</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>p</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>s</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7952</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>c</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>t</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3033</th>\n",
       "      <td>e</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>e</td>\n",
       "      <td>t</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>b</td>\n",
       "      <td>w</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>p</td>\n",
       "      <td>n</td>\n",
       "      <td>v</td>\n",
       "      <td>d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1364</th>\n",
       "      <td>e</td>\n",
       "      <td>x</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>b</td>\n",
       "      <td>k</td>\n",
       "      <td>...</td>\n",
       "      <td>f</td>\n",
       "      <td>w</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>n</td>\n",
       "      <td>a</td>\n",
       "      <td>g</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7259</th>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>y</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>p</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6567</th>\n",
       "      <td>p</td>\n",
       "      <td>f</td>\n",
       "      <td>s</td>\n",
       "      <td>n</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>f</td>\n",
       "      <td>c</td>\n",
       "      <td>n</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>s</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>p</td>\n",
       "      <td>w</td>\n",
       "      <td>o</td>\n",
       "      <td>e</td>\n",
       "      <td>w</td>\n",
       "      <td>v</td>\n",
       "      <td>l</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      E F0 F1 F2 F3 F4 F5 F6 F7 F8  ... F12 F13 F14 F15 F16 F17 F18 F19 F20  \\\n",
       "3156  p  x  s  w  f  c  f  w  n  g  ...   s   w   w   p   w   o   p   n   s   \n",
       "8088  e  k  s  n  f  n  a  c  b  n  ...   s   o   o   p   o   o   p   n   v   \n",
       "3247  e  x  y  n  t  n  f  c  b  u  ...   s   w   g   p   w   o   p   n   v   \n",
       "965   e  f  s  g  f  n  f  w  b  n  ...   s   w   w   p   w   o   e   k   s   \n",
       "1189  e  x  f  n  f  n  f  w  b  p  ...   s   w   w   p   w   o   e   n   s   \n",
       "7952  e  f  s  c  t  n  f  c  b  w  ...   s   w   w   p   w   t   p   w   v   \n",
       "3033  e  f  y  e  t  n  f  c  b  w  ...   s   p   w   p   w   o   p   n   v   \n",
       "1364  e  x  f  n  f  n  f  w  b  k  ...   f   w   w   p   w   o   e   n   a   \n",
       "7259  p  f  s  n  f  y  f  c  n  b  ...   s   p   w   p   w   o   e   w   v   \n",
       "6567  p  f  s  n  f  f  f  c  n  b  ...   s   p   w   p   w   o   e   w   v   \n",
       "\n",
       "     F21  \n",
       "3156   d  \n",
       "8088   l  \n",
       "3247   d  \n",
       "965    g  \n",
       "1189   g  \n",
       "7952   p  \n",
       "3033   d  \n",
       "1364   g  \n",
       "7259   p  \n",
       "6567   l  \n",
       "\n",
       "[10 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"../datasets/mushrooms.csv\")\n",
    "data.sample(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "After inspecting the data, we find that we're only intereted in the features labeled as `\"F0\", \"F1\", \"F2\", \"F20\", \"F21\"`, so we extract those as our data of interest along with, of course, the label `\"E\"`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_of_interest = data.loc[:, [\"E\", \"F0\", \"F1\", \"F2\", \"F20\", \"F21\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.1.3 How to Measure Similarity?\n",
    "Before we can measure the Euclidean distance between two mushrooms, we need to map the charcter codes for the features to numeric values in order to plug them into the equation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerically_encode(df):\n",
    "    \n",
    "    encoded_df = df.copy()\n",
    "    encoders = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        unique_categories = df.loc[:, col].unique()\n",
    "        unique_categories.sort() # in-place sorting\n",
    "    \n",
    "        encoder = {str: num for num, str in enumerate(unique_categories)}\n",
    "        encoders[col] = encoder\n",
    "    \n",
    "        encoded_df.loc[:, col] = df.loc[:, col].apply(lambda x: encoder[x])\n",
    "    \n",
    "    return encoded_df, encoders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We now encode our data and reterive the encoder dictionary for the label column to see how each label is encoded and be able to interpret the results of the classifier we're going to build."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'e': 0, 'p': 1}\n"
     ]
    }
   ],
   "source": [
    "encoded_data, encoders = numerically_encode(data_of_interest)\n",
    "print(encoders[\"E\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.1.4 k-NN in Action\n",
    "We start our implementation of the k-NN model by implementing a function that calculates the Euclidean distance between two mushrooms "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "def d(p1, p2):\n",
    "    \n",
    "    N = len(p1)\n",
    "    squared_distance = 0\n",
    "    \n",
    "    for i in range(N):\n",
    "        squared_distance += (p1[i] - p2[i]) ** 2\n",
    "        \n",
    "    return math.sqrt(squared_distance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can now implement the k-NN classifier by simply calculating the distances between the input we have and all the data in the training set, sort those in ascending fashion by the distance, pick the first k and then report the most common label in our chosen set of k data points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "\n",
    "def knn_classifier(new_x, k, X_train, y_train):\n",
    "\n",
    "    neighbors = [] # a list of tuples (distance_to_new_x, neighbor_label)\n",
    "    for x, y in zip(X_train, y_train):\n",
    "        distance = d(x, new_x)\n",
    "        neighbors.append((distance, y))\n",
    "\n",
    "    sorted_neighbors = sorted(neighbors, key=lambda n: n[0])\n",
    "    nearest_k_neighbors = sorted_neighbors[:k]\n",
    "    \n",
    "    labels_counter = Counter([label for _, label in nearest_k_neighbors])\n",
    "    most_voted_label = max(labels_counter.items(), key=lambda i: i[1])\n",
    "    \n",
    "    return most_voted_label[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Before we can test the k-NN classifier, which we did before in chapters 1, 3 with scikit-learn. However, as long as we're doing things from scratch, let's see how we can do it manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/pepo/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: FutureWarning: Method .as_matrix will be removed in a future version. Use .values instead.\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "shuffled_data = encoded_data.sample(frac=1., random_state=42)\n",
    "X, y = shuffled_data.loc[:, 'F0':], shuffled_data.loc[:, \"E\"]\n",
    "X, y = X.as_matrix(), y.as_matrix()\n",
    "\n",
    "X_train, y_train = X[:6125], y[:6125]\n",
    "X_test, y_test = X[6125:], y[6125:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can now run our classifier and see it in action and how it performs on the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error 0.110, Test Accuracy: 0.890\n"
     ]
    }
   ],
   "source": [
    "test_preds = [knn_classifier(x, 5, X_train, y_train) for x in X_test]\n",
    "\n",
    "losses = [1. if y_pred != y else 0. for y_pred, y in zip(test_preds, y_test)]\n",
    "test_error = (1. / len(test_preds)) * sum(losses)\n",
    "accuracy = 1. - test_error\n",
    "\n",
    "print(\"Test Error {:.3f}, Test Accuracy: {:.3f}\".format(test_error, accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "While this implementation is giving us a decent performance, it's ineffcient when it comes to time. We can verfiy that by running the `%timeit` magic against the prediction step and see"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1min 43s Â± 1.47 s per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [knn_classifier(x, 5, X_train, y_train) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### 5.1.5 Boosting Performance with NumPy\n",
    "\n",
    "NumPy fixes the problem with python that causes the above code's ineffciency. Instead of usind dynamically-typed and scattered containers, NumPy relies on data structures that have static pre-defined types which allow them to occupy contiguous memeory locations. These data startuctures are the `ndarray`, which we can find that they are the backbone of our `pandas` data frames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(X))\n",
    "print(type(y))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To start using `ndarray`s and utilize their effciency, we first need to understand one of its charactristics that play a key role in determining its behavior, which is its `shape`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8124, 5)\n",
      "(8124,)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Shapes determine if we can perform arithmetic operations on `ndarray`s. If the shapes are _compatible_, then arithmetic operation can be performed, and they are performed element-wise like we see in the following example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1.     0.5    0.25   0.125]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "four_ones = np.ones(shape=(4, ))\n",
    "powers_of_two = np.array([1, 2, 4, 8])\n",
    "\n",
    "print(four_ones / powers_of_two)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can take advantage of the broadcasting feature and rewrite our k-NN implementation bye getting rid of the nested for loops for calculating the distance and transfer them from python to NumPy optimized C/C++ code. We also change the voting code to use NumPy alternative and fully harness its powers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def faster_knn_classifier(new_x, k, X_train, y_train):\n",
    "    \n",
    "    neighbors_distances = np.sqrt(np.sum((X_train - new_x) ** 2, axis=1))\n",
    "        \n",
    "    sorted_neighbors_indecies = np.argsort(neighbors_distances)\n",
    "    nearest_k_neighbors_indecies = sorted_neighbors_indecies[:k]\n",
    "    nearest_k_neighbors_labels = y_train[nearest_k_neighbors_indecies]\n",
    "    \n",
    "    labels, votes = np.unique(nearest_k_neighbors_labels, return_counts=True)\n",
    "    most_voted_label_index = np.argmax(votes)\n",
    "    \n",
    "    return labels[most_voted_label_index]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Now we can test our new k-NN classifier and see how much faster it has become"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error 0.1176, Test Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "faster_test_preds = [\n",
    "    faster_knn_classifier(x, 1, X_train, y_train) for x in X_test\n",
    "]\n",
    "faster_losses = (faster_test_preds != y_test)\n",
    "faster_test_error = np.mean(faster_losses)\n",
    "\n",
    "print(\"Test Error {:.4f}, Test Accuracy: {:.4f}\".format(\n",
    "    faster_test_error, \n",
    "    1. - faster_test_error\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.41 s Â± 10.1 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit [faster_knn_classifier(x, 5, X_train, y_train) for x in X_test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5.2 A Better k-NN Classifier\n",
    "### 5.2.2 Using k-d Tress with scikit-learn\n",
    "After we saw how k-d trees can boost the nearst neighbors search, let's see that in action by using scikit-learn's implementation of the k-NN model that comes with a k-d trees implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Error 0.1176, Test Accuracy: 0.8824\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier(n_neighbors=5, algorithm='kd_tree')\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "sklearn_test_accuracy = classifier.score(X_test, y_test)\n",
    "\n",
    "print(\"Test Error {:.4f}, Test Accuracy: {:.4f}\".format(\n",
    "    1. - sklearn_test_accuracy, \n",
    "    sklearn_test_accuracy\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "21.1 ms Â± 1.49 ms per loop (mean Â± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit classifier.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2.3 Tuning the Value of k\n",
    "\n",
    "To start searching through the possible values of k in order to find the value that would return the best performing model, we need to craete another held out dataset that is used during this serach, thus leaving our test unseen. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "new_X_train, X_valid = X_train[:5525], X_train[5525:]\n",
    "new_y_train, y_valid = y_train[:5525], y_train[5525:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "With this new **_validation set_**, we can start looking through the best k value by iterating through the possible values and training a k-NN classifier and recording the best performing one on the training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 11, Best Validation Score: 0.8950\n",
      "Test Accuracy: 0.9005\n"
     ]
    }
   ],
   "source": [
    "best_score, best_k, best_classifier = 0., None, None\n",
    "for k in range(1, 21):\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k)\n",
    "        classifier.fit(new_X_train, new_y_train)\n",
    "        score = classifier.score(X_valid, y_valid)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_classifier = classifier\n",
    "\n",
    "print(\"Best k: {}, Best Validation Score: {:.4f}\".format(best_k, best_score))\n",
    "print(\"Test Accuracy: {:.4f}\".format(best_classifier.score(X_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "We can extend our linear search tuning algorithm into a grid search algorithm that searches through pairs of hyperparameters and reports the best configuration. The second hyperparameter we're going to search for is the `metric` and we're gonna see that automatic choice aligns with our expert's judgment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best k: 11, Best Metric: hamming, Best Validation Score: 0.9017\n",
      "Test Accuracy: 0.9065\n"
     ]
    }
   ],
   "source": [
    "best_score, best_k, best_metric, best_classifier = 0., -1, None, None\n",
    "for k in range(1, 21):\n",
    "    for metric in ['euclidean', 'manhattan', 'hamming', 'canberra']:\n",
    "        classifier = KNeighborsClassifier(n_neighbors=k, metric=metric)\n",
    "        classifier.fit(new_X_train, new_y_train)\n",
    "        score = classifier.score(X_valid, y_valid)\n",
    "        if score > best_score:\n",
    "            best_score = score\n",
    "            best_k = k\n",
    "            best_metric = metric\n",
    "            best_classifier = classifier\n",
    "\n",
    "print(\"Best k: {}, Best Metric: {}, Best Validation Score: {:.4f}\".format(\n",
    "    best_k, \n",
    "    best_metric, \n",
    "    best_score\n",
    "))\n",
    "print(\"Test Accuracy: {:.4f}\".format(best_classifier.score(X_test, y_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
